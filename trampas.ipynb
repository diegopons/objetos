{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM0McL/m+wC1R6oDkUysbR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegopons/objetos/blob/main/trampas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aw90uw0Bp2O",
        "outputId": "7c170d2b-a30f-4541-b07c-0354d194ff1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  imagenes_trampas.zip\n",
            "replace imagenes_trampas/Cordoba_22022022.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai pillow\n",
        "!unzip imagenes_trampas.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# --- La configuración de la API ya se hizo en la celda anterior ---\n",
        "try:\n",
        "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"La variable de entorno GOOGLE_API_KEY no está configurada. Ejecuta la celda 3.\")\n",
        "    genai.configure(api_key=api_key)\n",
        "except Exception as e:\n",
        "    print(f\"Error de configuración: {e}\")\n",
        "    # exit() # Se comenta para no detener el cuaderno de Colab\n",
        "\n",
        "def analizar_imagen(ruta_imagen, model):\n",
        "    \"\"\"\n",
        "    Analiza una única imagen para contar e identificar lepidópteros.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(ruta_imagen)\n",
        "        prompt_detallado = \"\"\"\n",
        "        Analiza la imagen e identifica y cuenta todos los lepidópteros.\n",
        "        Proporciona tu respuesta exclusivamente en formato JSON con la siguiente estructura:\n",
        "        {\n",
        "          \"conteo_total\": <numero>,\n",
        "          \"especies_identificadas\": [\n",
        "            {\n",
        "              \"nombre_cientifico\": \"...\",\n",
        "              \"nombre_comun\": \"...\",\n",
        "              \"cantidad\": <numero_de_esta_especie>\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "        Si no encuentras ninguno, devuelve \"conteo_total\": 0.\n",
        "        \"\"\"\n",
        "        response = model.generate_content([prompt_detallado, img])\n",
        "        cleaned_json = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        return json.loads(cleaned_json)\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Error al analizar la imagen {os.path.basename(ruta_imagen)}: {e}\")\n",
        "        return None\n",
        "\n",
        "def procesar_directorio(directorio_imagenes):\n",
        "    \"\"\"\n",
        "    Procesa todas las imágenes en un directorio, extrae metadatos y genera un\n",
        "    archivo de resultados consolidado.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(directorio_imagenes):\n",
        "        print(f\"Error: El directorio '{directorio_imagenes}' no existe.\")\n",
        "        return\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    resultados_finales = {\"avistamientos\": []}\n",
        "\n",
        "    archivos_a_procesar = [f for f in os.listdir(directorio_imagenes) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    total_archivos = len(archivos_a_procesar)\n",
        "\n",
        "    print(f\"Se encontraron {total_archivos} imágenes en '{directorio_imagenes}'.\")\n",
        "\n",
        "    for i, nombre_archivo in enumerate(archivos_a_procesar):\n",
        "        print(f\"\\nProcesando imagen {i+1}/{total_archivos}: {nombre_archivo}...\")\n",
        "\n",
        "        try:\n",
        "            partes = os.path.splitext(nombre_archivo)[0].split('_')\n",
        "            localidad = partes[0]\n",
        "            fecha = partes[1]\n",
        "            ruta_completa = os.path.join(directorio_imagenes, nombre_archivo)\n",
        "        except IndexError:\n",
        "            print(f\"  -> Advertencia: El archivo '{nombre_archivo}' no sigue el formato de nombre esperado. Se omitirá.\")\n",
        "            continue\n",
        "\n",
        "        resultado_ia = analizar_imagen(ruta_completa, model)\n",
        "\n",
        "        if resultado_ia and resultado_ia.get(\"conteo_total\", 0) > 0:\n",
        "            for especie in resultado_ia.get(\"especies_identificadas\", []):\n",
        "                registro = {\n",
        "                    \"localidad\": localidad,\n",
        "                    \"fecha\": fecha,\n",
        "                    \"nombre_cientifico\": especie.get(\"nombre_cientifico\"),\n",
        "                    \"nombre_comun\": especie.get(\"nombre_comun\"),\n",
        "                    \"cantidad\": especie.get(\"cantidad\"),\n",
        "                    \"archivo_origen\": nombre_archivo\n",
        "                }\n",
        "                resultados_finales[\"avistamientos\"].append(registro)\n",
        "            print(f\"  -> Éxito: Se encontraron {resultado_ia['conteo_total']} individuos.\")\n",
        "        else:\n",
        "            print(\"  -> No se encontraron lepidópteros en esta imagen o hubo un error.\")\n",
        "\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    ruta_salida = \"resultados.json\"\n",
        "    print(f\"\\nProceso completado. Guardando resultados consolidados en '{ruta_salida}'...\")\n",
        "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_finales, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(\"¡Archivo de resultados generado con éxito!\")\n",
        "\n",
        "\n",
        "# --- ¡AQUÍ SE INICIA EL PROCESO! ---\n",
        "directorio_de_entrada = \"imagenes_trampas\" # Esta es la carpeta que descomprimiste\n",
        "procesar_directorio(directorio_de_entrada)"
      ],
      "metadata": {
        "id": "px8Sj6PeFj2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "523d6ede"
      },
      "source": [
        "# Task\n",
        "Generate the geographical location based on the locality name in the image filenames and classify the lepidoptera species in each image using the Gemini API. The output should be a JSON file containing the filename, geographical coordinates (latitude and longitude), and the classified species for each image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b187d9de"
      },
      "source": [
        "## Modify data extraction\n",
        "\n",
        "### Subtask:\n",
        "Update the code to extract the location name from the filename consistently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b65a8022"
      },
      "source": [
        "**Reasoning**:\n",
        "The current code for extracting locality and date from filenames is too rigid and fails on filenames that don't strictly follow the \"locality_date\" format. I need to modify the code to handle more flexible filename structures where the locality name can contain underscores. I will use regular expressions to capture the part before the last underscore as the locality and the part after the last underscore before the extension as the date.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8080b923"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import re # Import the re module for regular expressions\n",
        "\n",
        "# --- La configuración de la API ya se hizo en la celda anterior ---\n",
        "try:\n",
        "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"La variable de entorno GOOGLE_API_KEY no está configurada. Ejecuta la celda 3.\")\n",
        "    genai.configure(api_key=api_key)\n",
        "except Exception as e:\n",
        "    print(f\"Error de configuración: {e}\")\n",
        "    # exit() # Se comenta para no detener el cuaderno de Colab\n",
        "\n",
        "def analizar_imagen(ruta_imagen, model):\n",
        "    \"\"\"\n",
        "    Analiza una única imagen para contar e identificar lepidópteros.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(ruta_imagen)\n",
        "        prompt_detallado = \"\"\"\n",
        "        Analiza la imagen e identifica y cuenta todos los lepidópteros.\n",
        "        Proporciona tu respuesta exclusivamente en formato JSON con la siguiente estructura:\n",
        "        {\n",
        "          \"conteo_total\": <numero>,\n",
        "          \"especies_identificadas\": [\n",
        "            {\n",
        "              \"nombre_cientifico\": \"...\",\n",
        "              \"nombre_comun\": \"...\",\n",
        "              \"cantidad\": <numero_de_esta_especie>\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "        Si no encuentras ninguno, devuelve \"conteo_total\": 0.\n",
        "        \"\"\"\n",
        "        response = model.generate_content([prompt_detallado, img])\n",
        "        cleaned_json = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        return json.loads(cleaned_json)\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Error al analizar la imagen {os.path.basename(ruta_imagen)}: {e}\")\n",
        "        return None\n",
        "\n",
        "def procesar_directorio(directorio_imagenes):\n",
        "    \"\"\"\n",
        "    Procesa todas las imágenes en un directorio, extrae metadatos y genera un\n",
        "    archivo de resultados consolidado.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(directorio_imagenes):\n",
        "        print(f\"Error: El directorio '{directorio_imagenes}' no existe.\")\n",
        "        return\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    resultados_finales = {\"avistamientos\": []}\n",
        "\n",
        "    archivos_a_procesar = [f for f in os.listdir(directorio_imagenes) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    total_archivos = len(archivos_a_procesar)\n",
        "\n",
        "    print(f\"Se encontraron {total_archivos} imágenes en '{directorio_imagenes}'.\")\n",
        "\n",
        "    for i, nombre_archivo in enumerate(archivos_a_procesar):\n",
        "        print(f\"\\nProcesando imagen {i+1}/{total_archivos}: {nombre_archivo}...\")\n",
        "\n",
        "        try:\n",
        "            # Use regex to extract locality and date\n",
        "            match = re.match(r\"(.+)_(\\d{8})\\..+\", nombre_archivo)\n",
        "            if match:\n",
        "                localidad = match.group(1)\n",
        "                fecha = match.group(2)\n",
        "                ruta_completa = os.path.join(directorio_imagenes, nombre_archivo)\n",
        "            else:\n",
        "                print(f\"  -> Advertencia: El archivo '{nombre_archivo}' no sigue el formato de nombre esperado (localidad_YYYYMMDD). Se omitirá.\")\n",
        "                continue\n",
        "\n",
        "        except IndexError:\n",
        "            print(f\"  -> Advertencia: Error al parsear el nombre de archivo '{nombre_archivo}'. Se omitirá.\")\n",
        "            continue\n",
        "\n",
        "        resultado_ia = analizar_imagen(ruta_completa, model)\n",
        "\n",
        "        if resultado_ia and resultado_ia.get(\"conteo_total\", 0) > 0:\n",
        "            for especie in resultado_ia.get(\"especies_identificadas\", []):\n",
        "                registro = {\n",
        "                    \"localidad\": localidad,\n",
        "                    \"fecha\": fecha,\n",
        "                    \"nombre_cientifico\": especie.get(\"nombre_cientifico\"),\n",
        "                    \"nombre_comun\": especie.get(\"nombre_comun\"),\n",
        "                    \"cantidad\": especie.get(\"cantidad\"),\n",
        "                    \"archivo_origen\": nombre_archivo\n",
        "                }\n",
        "                resultados_finales[\"avistamientos\"].append(registro)\n",
        "            print(f\"  -> Éxito: Se encontraron {resultado_ia['conteo_total']} individuos.\")\n",
        "        else:\n",
        "            print(\"  -> No se encontraron lepidópteros en esta imagen o hubo un error.\")\n",
        "\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    ruta_salida = \"resultados.json\"\n",
        "    print(f\"\\nProceso completado. Guardando resultados consolidados en '{ruta_salida}'...\")\n",
        "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_finales, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(\"¡Archivo de resultados generado con éxito!\")\n",
        "\n",
        "\n",
        "# --- ¡AQUÍ SE INICIA EL PROCESO! ---\n",
        "directorio_de_entrada = \"imagenes_trampas\" # Esta es la carpeta que descomprimiste\n",
        "procesar_directorio(directorio_de_entrada)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa5937cb"
      },
      "source": [
        "## Geolocate locations\n",
        "\n",
        "### Subtask:\n",
        "Add a step to use a geocoding service (like Nominatim with Geopy) to find the latitude and longitude for each unique locality name found in the filenames.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43f91c42"
      },
      "source": [
        "**Reasoning**:\n",
        "Add geocoding functionality to the script using Nominatim to get coordinates for each unique locality and include them in the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1958b09"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from geopy.geocoders import Nominatim # Import Nominatim\n",
        "\n",
        "# --- La configuración de la API ya se hizo en la celda anterior ---\n",
        "try:\n",
        "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"La variable de entorno GOOGLE_API_KEY no está configurada. Ejecuta la celda 3.\")\n",
        "    genai.configure(api_key=api_key)\n",
        "except Exception as e:\n",
        "    print(f\"Error de configuración: {e}\")\n",
        "    # exit() # Se comenta para no detener el cuaderno de Colab\n",
        "\n",
        "def analizar_imagen(ruta_imagen, model):\n",
        "    \"\"\"\n",
        "    Analiza una única imagen para contar e identificar lepidópteros.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(ruta_imagen)\n",
        "        prompt_detallado = \"\"\"\n",
        "        Analiza la imagen e identifica y cuenta todos los lepidópteros.\n",
        "        Proporciona tu respuesta exclusivamente en formato JSON con la siguiente estructura:\n",
        "        {\n",
        "          \"conteo_total\": <numero>,\n",
        "          \"especies_identificadas\": [\n",
        "            {\n",
        "              \"nombre_cientifico\": \"...\",\n",
        "              \"nombre_comun\": \"...\",\n",
        "              \"cantidad\": <numero_de_esta_especie>\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "        Si no encuentras ninguno, devuelve \"conteo_total\": 0.\n",
        "        \"\"\"\n",
        "        response = model.generate_content([prompt_detallado, img])\n",
        "        cleaned_json = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        return json.loads(cleaned_json)\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Error al analizar la imagen {os.path.basename(ruta_imagen)}: {e}\")\n",
        "        return None\n",
        "\n",
        "def procesar_directorio(directorio_imagenes):\n",
        "    \"\"\"\n",
        "    Procesa todas las imágenes en un directorio, extrae metadatos y genera un\n",
        "    archivo de resultados consolidado, including geocoded locations.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(directorio_imagenes):\n",
        "        print(f\"Error: El directorio '{directorio_imagenes}' no existe.\")\n",
        "        return\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    resultados_finales = {\"avistamientos\": []}\n",
        "\n",
        "    archivos_a_procesar = [f for f in os.listdir(directorio_imagenes) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    total_archivos = len(archivos_a_procesar)\n",
        "\n",
        "    # Initialize geolocator and dictionary to store coordinates\n",
        "    geolocator = Nominatim(user_agent=\"lepidoptera_analyzer\")\n",
        "    geocoding_results = {}\n",
        "\n",
        "    print(f\"Se encontraron {total_archivos} imágenes en '{directorio_imagenes}'.\")\n",
        "\n",
        "    for i, nombre_archivo in enumerate(archivos_a_procesar):\n",
        "        print(f\"\\nProcesando imagen {i+1}/{total_archivos}: {nombre_archivo}...\")\n",
        "\n",
        "        try:\n",
        "            match = re.match(r\"(.+)_(\\d{8})\\..+\", nombre_archivo)\n",
        "            if match:\n",
        "                localidad = match.group(1)\n",
        "                fecha = match.group(2)\n",
        "                ruta_completa = os.path.join(directorio_imagenes, nombre_archivo)\n",
        "            else:\n",
        "                print(f\"  -> Advertencia: El archivo '{nombre_archivo}' no sigue el formato de nombre esperado (localidad_YYYYMMDD). Se omitirá.\")\n",
        "                continue\n",
        "\n",
        "        except IndexError:\n",
        "            print(f\"  -> Advertencia: Error al parsear el nombre de archivo '{nombre_archivo}'. Se omitirá.\")\n",
        "            continue\n",
        "\n",
        "        # Geocode the locality if not already done\n",
        "        if localidad not in geocoding_results:\n",
        "            print(f\"  -> Geocodificando localidad: {localidad}...\")\n",
        "            try:\n",
        "                location = geolocator.geocode(localidad)\n",
        "                if location:\n",
        "                    geocoding_results[localidad] = {\"latitude\": location.latitude, \"longitude\": location.longitude}\n",
        "                    print(f\"    -> Encontrado: Latitud {location.latitude}, Longitud {location.longitude}\")\n",
        "                else:\n",
        "                    geocoding_results[localidad] = {\"latitude\": None, \"longitude\": None}\n",
        "                    print(\"    -> No se encontraron coordenadas.\")\n",
        "            except Exception as e:\n",
        "                geocoding_results[localidad] = {\"latitude\": None, \"longitude\": None}\n",
        "                print(f\"    -> Error durante la geocodificación: {e}\")\n",
        "            time.sleep(1.5) # Small delay to respect Nominatim usage policy\n",
        "\n",
        "        # Get coordinates for the current locality\n",
        "        coords = geocoding_results.get(localidad, {\"latitude\": None, \"longitude\": None})\n",
        "\n",
        "        resultado_ia = analizar_imagen(ruta_completa, model)\n",
        "\n",
        "        if resultado_ia and resultado_ia.get(\"conteo_total\", 0) > 0:\n",
        "            for especie in resultado_ia.get(\"especies_identificadas\", []):\n",
        "                registro = {\n",
        "                    \"localidad\": localidad,\n",
        "                    \"fecha\": fecha,\n",
        "                    \"latitude\": coords[\"latitude\"], # Add latitude\n",
        "                    \"longitude\": coords[\"longitude\"], # Add longitude\n",
        "                    \"nombre_cientifico\": especie.get(\"nombre_cientifico\"),\n",
        "                    \"nombre_comun\": especie.get(\"nombre_comun\"),\n",
        "                    \"cantidad\": especie.get(\"cantidad\"),\n",
        "                    \"archivo_origen\": nombre_archivo\n",
        "                }\n",
        "                resultados_finales[\"avistamientos\"].append(registro)\n",
        "            print(f\"  -> Éxito: Se encontraron {resultado_ia['conteo_total']} individuos.\")\n",
        "        else:\n",
        "            print(\"  -> No se encontraron lepidópteros en esta imagen o hubo un error.\")\n",
        "\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    ruta_salida = \"resultados.json\"\n",
        "    print(f\"\\nProceso completado. Guardando resultados consolidados en '{ruta_salida}'...\")\n",
        "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_finales, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(\"¡Archivo de resultados generado con éxito!\")\n",
        "\n",
        "\n",
        "# --- ¡AQUÍ SE INICIA EL PROCESO! ---\n",
        "directorio_de_entrada = \"imagenes_trampas\" # Esta es la carpeta que descomprimiste\n",
        "procesar_directorio(directorio_de_entrada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ee88f2"
      },
      "source": [
        "## Enhance ai prompt for species classification\n",
        "\n",
        "### Subtask:\n",
        "Modify the prompt sent to the Gemini model to encourage more specific species identification and include confidence scores if possible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51c71aad"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `prompt_detallado` in the `analizar_imagen` function to request more specific species identification and confidence scores, and update the expected JSON structure in the prompt accordingly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6c42900"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "# --- La configuración de la API ya se hizo en la celda anterior ---\n",
        "try:\n",
        "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"La variable de entorno GOOGLE_API_KEY no está configurada. Ejecuta la celda 3.\")\n",
        "    genai.configure(api_key=api_key)\n",
        "except Exception as e:\n",
        "    print(f\"Error de configuración: {e}\")\n",
        "    # exit() # Se comenta para no detener el cuaderno de Colab\n",
        "\n",
        "def analizar_imagen(ruta_imagen, model):\n",
        "    \"\"\"\n",
        "    Analiza una única imagen para contar e identificar lepidópteros,\n",
        "    requesting specific species and confidence scores.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(ruta_imagen)\n",
        "        # Updated prompt requesting specific identification and confidence\n",
        "        prompt_detallado = \"\"\"\n",
        "        Analiza la imagen e identifica y cuenta todos los lepidópteros presentes.\n",
        "        Para cada lepidóptero identificado, proporciona el nombre científico lo más específico posible,\n",
        "        el nombre común si es conocido, la cantidad de individuos de esa especie,\n",
        "        y un puntaje de confianza (confidence score) para la identificación en una escala de 0 a 1.0.\n",
        "\n",
        "        Proporciona tu respuesta exclusivamente en formato JSON con la siguiente estructura:\n",
        "        {\n",
        "          \"conteo_total\": <numero total de lepidópteros>,\n",
        "          \"especies_identificadas\": [\n",
        "            {\n",
        "              \"nombre_cientifico\": \"...\",\n",
        "              \"nombre_comun\": \"...\",\n",
        "              \"cantidad\": <numero de esta especie>,\n",
        "              \"confidence_score\": <puntaje de confianza, 0.0 a 1.0>\n",
        "            }\n",
        "            // ... más especies si hay ...\n",
        "          ]\n",
        "        }\n",
        "        Si no encuentras ningún lepidóptero, devuelve \"conteo_total\": 0 y una lista vacía para \"especies_identificadas\".\n",
        "        Asegúrate de que la respuesta sea solo el bloque JSON válido.\n",
        "        \"\"\"\n",
        "        response = model.generate_content([prompt_detallado, img])\n",
        "        # Clean potential markdown formatting from the response\n",
        "        cleaned_json = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        return json.loads(cleaned_json)\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Error al analizar la imagen {os.path.basename(ruta_imagen)}: {e}\")\n",
        "        # Return a structure consistent with no findings or error\n",
        "        return {\"conteo_total\": 0, \"especies_identificadas\": []}\n",
        "\n",
        "\n",
        "def procesar_directorio(directorio_imagenes):\n",
        "    \"\"\"\n",
        "    Procesa todas las imágenes en un directorio, extrae metadatos y genera un\n",
        "    archivo de resultados consolidado, including geocoded locations.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(directorio_imagenes):\n",
        "        print(f\"Error: El directorio '{directorio_imagenes}' no existe.\")\n",
        "        return\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    resultados_finales = {\"avistamientos\": []}\n",
        "\n",
        "    archivos_a_procesar = [f for f in os.listdir(directorio_imagenes) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    total_archivos = len(archivos_a_procesar)\n",
        "\n",
        "    # Initialize geolocator and dictionary to store coordinates\n",
        "    geolocator = Nominatim(user_agent=\"lepidoptera_analyzer\")\n",
        "    geocoding_results = {}\n",
        "\n",
        "    print(f\"Se encontraron {total_archivos} imágenes en '{directorio_imagenes}'.\")\n",
        "\n",
        "    for i, nombre_archivo in enumerate(archivos_a_procesar):\n",
        "        print(f\"\\nProcesando imagen {i+1}/{total_archivos}: {nombre_archivo}...\")\n",
        "\n",
        "        try:\n",
        "            match = re.match(r\"(.+)_(\\d{8})\\..+\", nombre_archivo)\n",
        "            if match:\n",
        "                localidad = match.group(1)\n",
        "                fecha = match.group(2)\n",
        "                ruta_completa = os.path.join(directorio_imagenes, nombre_archivo)\n",
        "            else:\n",
        "                print(f\"  -> Advertencia: El archivo '{nombre_archivo}' no sigue el formato de nombre esperado (localidad_YYYYMMDD). Se omitirá.\")\n",
        "                continue\n",
        "\n",
        "        except IndexError:\n",
        "            print(f\"  -> Advertencia: Error al parsear el nombre de archivo '{nombre_archivo}'. Se omitirá.\")\n",
        "            continue\n",
        "\n",
        "        # Geocode the locality if not already done\n",
        "        if localidad not in geocoding_results:\n",
        "            print(f\"  -> Geocodificando localidad: {localidad}...\")\n",
        "            try:\n",
        "                location = geolocator.geocode(localidad)\n",
        "                if location:\n",
        "                    geocoding_results[localidad] = {\"latitude\": location.latitude, \"longitude\": location.longitude}\n",
        "                    print(f\"    -> Encontrado: Latitud {location.latitude}, Longitud {location.longitude}\")\n",
        "                else:\n",
        "                    geocoding_results[localidad] = {\"latitude\": None, \"longitude\": None}\n",
        "                    print(\"    -> No se encontraron coordenadas.\")\n",
        "            except Exception as e:\n",
        "                geocoding_results[localidad] = {\"latitude\": None, \"longitude\": None}\n",
        "                print(f\"    -> Error durante la geocodificación: {e}\")\n",
        "            time.sleep(1.5) # Small delay to respect Nominatim usage policy\n",
        "\n",
        "        # Get coordinates for the current locality\n",
        "        coords = geocoding_results.get(localidad, {\"latitude\": None, \"longitude\": None})\n",
        "\n",
        "        resultado_ia = analizar_imagen(ruta_completa, model)\n",
        "\n",
        "        # Check if resultado_ia is a valid dictionary with species_identificadas\n",
        "        if resultado_ia and isinstance(resultado_ia, dict) and resultado_ia.get(\"conteo_total\", 0) > 0 and \"especies_identificadas\" in resultado_ia:\n",
        "             for especie in resultado_ia.get(\"especies_identificadas\", []):\n",
        "                registro = {\n",
        "                    \"localidad\": localidad,\n",
        "                    \"fecha\": fecha,\n",
        "                    \"latitude\": coords[\"latitude\"], # Add latitude\n",
        "                    \"longitude\": coords[\"longitude\"], # Add longitude\n",
        "                    \"nombre_cientifico\": especie.get(\"nombre_cientifico\"),\n",
        "                    \"nombre_comun\": especie.get(\"nombre_comun\"),\n",
        "                    \"cantidad\": especie.get(\"cantidad\"),\n",
        "                    \"confidence_score\": especie.get(\"confidence_score\"), # Add confidence score\n",
        "                    \"archivo_origen\": nombre_archivo\n",
        "                }\n",
        "                resultados_finales[\"avistamientos\"].append(registro)\n",
        "             print(f\"  -> Éxito: Se encontraron {resultado_ia.get('conteo_total', 'N/A')} individuos.\")\n",
        "        else:\n",
        "            print(\"  -> No se encontraron lepidópteros en esta imagen o hubo un error.\")\n",
        "\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    ruta_salida = \"resultados.json\"\n",
        "    print(f\"\\nProceso completado. Guardando resultados consolidados en '{ruta_salida}'...\")\n",
        "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_finales, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(\"¡Archivo de resultados generado con éxito!\")\n",
        "\n",
        "\n",
        "# --- ¡AQUÍ SE INICIA EL PROCESO! ---\n",
        "directorio_de_entrada = \"imagenes_trampas\" # Esta es la carpeta que descomprimiste\n",
        "procesar_directorio(directorio_de_entrada)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5747c1d3"
      },
      "source": [
        "## (optional) external species verification\n",
        "\n",
        "### Subtask:\n",
        "If the Gemini model's response is not specific enough, explore using external databases or APIs (if available and feasible) to verify or refine the identified species based on the locality and image features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca1bf5d1"
      },
      "source": [
        "**Reasoning**:\n",
        "Analyze the `resultados.json` file to check the specificity of the `nombre_cientifico` and the presence and informativeness of the `confidence_score`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e27cf5d0"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the results from the JSON file\n",
        "try:\n",
        "    with open('resultados.json', 'r', encoding='utf-8') as f:\n",
        "        resultados = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: resultados.json not found. Please run the previous cells first.\")\n",
        "    resultados = {\"avistamientos\": []}\n",
        "\n",
        "# Convert the avistamientos list to a pandas DataFrame for easier analysis\n",
        "df_resultados = pd.DataFrame(resultados.get(\"avistamientos\", []))\n",
        "\n",
        "# Display information about the dataframe\n",
        "print(\"DataFrame Info:\")\n",
        "df_resultados.info()\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"\\nFirst 5 rows of the results:\")\n",
        "display(df_resultados.head())\n",
        "\n",
        "# Check the unique values and frequency of 'nombre_cientifico'\n",
        "print(\"\\nUnique values and counts for 'nombre_cientifico':\")\n",
        "display(df_resultados['nombre_cientifico'].value_counts())\n",
        "\n",
        "# Check for the presence and range of 'confidence_score'\n",
        "print(\"\\nDescription of 'confidence_score':\")\n",
        "display(df_resultados['confidence_score'].describe())\n",
        "\n",
        "# Check for rows where 'confidence_score' is missing or None\n",
        "print(\"\\nRows with missing 'confidence_score':\")\n",
        "display(df_resultados[df_resultados['confidence_score'].isnull()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0014b8c1"
      },
      "source": [
        "**Reasoning**:\n",
        "The analysis shows that the Gemini model provided scientific names, but one is only at the family level (\"Noctuidae\"). The confidence scores are present and seem informative. Since one identification is not specific, exploring external databases for potential refinement is relevant to the subtask. I will research publicly available external databases or APIs for lepidoptera species verification based on location and potentially image features or other provided information. I will then evaluate the feasibility and decide whether to pursue integration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "060d221a"
      },
      "source": [
        "# Researching potential external databases/APIs for lepidoptera verification\n",
        "print(\"Researching external databases/APIs for lepidoptera verification...\")\n",
        "\n",
        "# Potential candidates:\n",
        "# 1. iNaturalist API (https://api.inaturalist.org/v1/docs/) - Allows searching for observations by location, taxon, etc. Can also suggest taxa based on images. Requires API key for higher usage limits.\n",
        "# 2. GBIF API (https://www.gbif.org/developer/occurrence) - Global Biodiversity Information Facility. Provides occurrence data. Can filter by taxonomy, location, date. No API key required for basic access.\n",
        "# 3. Lepidoptera-specific databases (e.g., LepIndex, World Lepidoptera Database) - Might be useful for taxonomic lookups but less likely to support location-based or image-based verification directly via API.\n",
        "\n",
        "# Evaluation of feasibility:\n",
        "# - iNaturalist API: Seems promising as it supports image-based suggestions and location filtering. Requires API key, which might add a setup step. Rate limits need to be considered.\n",
        "# - GBIF API: Excellent for checking if a species has been recorded in a specific location. Does not support image-based verification. Useful for cross-referencing.\n",
        "# - Lepidoptera-specific databases: Primarily taxonomic, less useful for this verification task based on location and image features.\n",
        "\n",
        "# Decision:\n",
        "# iNaturalist API seems the most suitable for potentially refining identifications based on location and image context, as it has features for both. GBIF could be a secondary source for occurrence verification.\n",
        "\n",
        "print(\"\\nEvaluation complete.\")\n",
        "print(\"iNaturalist API is a potential candidate for external verification.\")\n",
        "print(\"Integration would involve:\")\n",
        "print(\"1. Obtaining an API key (if necessary for required usage).\")\n",
        "print(\"2. Constructing API requests with locality (latitude/longitude) and potentially image data or the initial identification from Gemini.\")\n",
        "print(\"3. Parsing the API response to get suggested species and associated confidence/information.\")\n",
        "print(\"4. Comparing/combining the external results with the Gemini results.\")\n",
        "print(\"5. Handling API rate limits and errors.\")\n",
        "\n",
        "# Since the Gemini model provided relatively specific names for most entries (except one family-level),\n",
        "# and the dataset is small, integrating an external API for verification at this point\n",
        "# might be an overcomplication for this specific task demonstration.\n",
        "# However, for a larger, production-level system, it would be a valuable step.\n",
        "\n",
        "# Given the constraints and the current dataset size/results,\n",
        "# we will document this research and the potential for future integration\n",
        "# but will not implement the external API integration in this iteration.\n",
        "# The Gemini model's output, combined with the confidence scores, provides a reasonable\n",
        "# starting point for this demonstration.\n",
        "\n",
        "print(\"\\nDecision: Not pursuing external API integration in this iteration due to small dataset size and complexity vs. current needs. Research documented.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1a331b7"
      },
      "source": [
        "## Integrate geolocation and species data\n",
        "\n",
        "### Subtask:\n",
        "Combine the geolocation data and the detailed species information obtained from the AI analysis and optional external verification into the final results structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65a489b0"
      },
      "source": [
        "## Update results output\n",
        "\n",
        "### Subtask:\n",
        "Modify the code to include the geographical coordinates and more detailed species information in the `resultados.json` file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e3661a3"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the `procesar_directorio` function to ensure that latitude, longitude, and detailed species information including confidence score are correctly included in the `registro` dictionary and that the final results are written to 'resultados.json' with the specified formatting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5592c842"
      },
      "source": [
        "# Reviewing the procesar_directorio function implementation based on previous steps.\n",
        "# No code modifications are needed as the previous steps already implemented the required logic.\n",
        "\n",
        "# The procesar_directorio function already:\n",
        "# 1. Extracts locality and date from filenames.\n",
        "# 2. Performs geocoding for unique localities and stores latitude and longitude.\n",
        "# 3. Calls analizar_imagen to get detailed species information including confidence_score.\n",
        "# 4. Creates a 'registro' dictionary that includes 'localidad', 'fecha', 'latitude', 'longitude',\n",
        "#    'nombre_cientifico', 'nombre_comun', 'cantidad', 'confidence_score', and 'archivo_origen'.\n",
        "# 5. Appends these 'registro' dictionaries to the 'avistamientos' list in 'resultados_finales'.\n",
        "# 6. Writes 'resultados_finales' to 'resultados.json' with ensure_ascii=False and indent=4.\n",
        "\n",
        "# Therefore, no code changes are necessary for this subtask.\n",
        "print(\"Review of procesar_directorio function complete. The required fields (latitude, longitude, detailed species info including confidence_score) are already included in the 'registro' dictionary and the output JSON.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8845b87b"
      },
      "source": [
        "## Refine and test\n",
        "\n",
        "### Subtask:\n",
        "Test the updated script with the existing images and handle potential errors (e.g., location not found, ambiguous species identification).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90cb8a7d"
      },
      "source": [
        "**Reasoning**:\n",
        "Run the complete script again to process the images with the updated logic and observe the output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31b4051a"
      },
      "source": [
        "# --- ¡AQUÍ SE INICIA EL PROCESO! ---\n",
        "directorio_de_entrada = \"imagenes_trampas\" # Esta es la carpeta que descomprimiste\n",
        "procesar_directorio(directorio_de_entrada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb55b509"
      },
      "source": [
        "**Reasoning**:\n",
        "Examine the generated resultados.json file to ensure it contains the expected fields and check for data consistency, particularly for entries that previously caused warnings or had less specific AI results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8be0a215"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the results from the JSON file\n",
        "try:\n",
        "    with open('resultados.json', 'r', encoding='utf-8') as f:\n",
        "        resultados = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: resultados.json not found.\")\n",
        "    resultados = {\"avistamientos\": []}\n",
        "\n",
        "# Convert the avistamientos list to a pandas DataFrame for easier analysis\n",
        "df_resultados = pd.DataFrame(resultados.get(\"avistamientos\", []))\n",
        "\n",
        "# Display the full DataFrame to inspect all entries\n",
        "print(\"Full DataFrame from resultados.json:\")\n",
        "display(df_resultados)\n",
        "\n",
        "# Check the data types and non-null counts\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df_resultados.info()\n",
        "\n",
        "# Check for missing values in key columns\n",
        "print(\"\\nMissing values per column:\")\n",
        "display(df_resultados.isnull().sum())\n",
        "\n",
        "# Check unique localities and their geocoding status\n",
        "print(\"\\nUnique localities and geocoding status:\")\n",
        "display(df_resultados[['localidad', 'latitude', 'longitude']].drop_duplicates())\n",
        "\n",
        "# Check the unique values and frequency of 'nombre_cientifico' and 'nombre_comun'\n",
        "print(\"\\nUnique values and counts for 'nombre_cientifico':\")\n",
        "display(df_resultados['nombre_cientifico'].value_counts())\n",
        "print(\"\\nUnique values and counts for 'nombre_comun':\")\n",
        "display(df_resultados['nombre_comun'].value_counts())\n",
        "\n",
        "# Check the distribution of 'cantidad'\n",
        "print(\"\\nDistribution of 'cantidad':\")\n",
        "display(df_resultados['cantidad'].value_counts())\n",
        "\n",
        "# Check the distribution and descriptive statistics of 'confidence_score'\n",
        "print(\"\\nDescription of 'confidence_score':\")\n",
        "display(df_resultados['confidence_score'].describe())\n",
        "\n",
        "# Identify entries with lower confidence scores or less specific identifications\n",
        "print(\"\\nEntries with confidence score < 0.8 or less specific scientific names:\")\n",
        "display(df_resultados[(df_resultados['confidence_score'] < 0.8) | (~df_resultados['nombre_cientifico'].str.contains(' '))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d541ec8b"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The script successfully processed 4 out of 8 image files based on a specific `localidad_YYYYMMDD.ext` naming convention. The other 4 files were skipped due to not matching this format.\n",
        "*   Geocoding was successful for 3 out of the 4 processed unique localities (\"VillaDolores\", \"Tuclame\", and \"Cordoba\"), providing latitude and longitude coordinates.\n",
        "*   Geocoding failed for one locality (\"DeanFunes\"), resulting in missing latitude and longitude values in the output for entries associated with this locality.\n",
        "*   The AI model identified lepidoptera species in all 4 processed images.\n",
        "*   One species identification was at the family level (\"Noctuidae\") with a confidence score of 0.60, while the others were more specific (species level) with higher confidence scores (ranging from 0.70 to 0.95).\n",
        "*   The final output JSON file (`resultados.json`) contains the filename, extracted locality and date, geographical coordinates (where available), AI-classified scientific and common names, quantity, and confidence scores for each identified lepidoptera sighting.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Implement more flexible filename parsing or add a configuration step to define expected filename patterns to process a wider variety of inputs.\n",
        "*   Consider implementing a fallback mechanism or using an alternative geocoding service for localities that Nominatim cannot resolve to improve data completeness.\n"
      ]
    }
  ]
}